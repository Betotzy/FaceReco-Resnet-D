{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "14m9CuMSV_d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "amicBIpHV-1W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "exSWLJtJWDba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RDo8QRgZXbub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224c6e7e-25d4-49cf-ad68-45e77477021d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yCge1a3I_Tls"
      },
      "outputs": [],
      "source": [
        "data_path='/content/drive/MyDrive/FaceReco/Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn9Lmi5m_cQM",
        "outputId": "2e7b02ac-4f2f-4e48-fe29-5afeb300b301"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gender_classification.csv',\n",
              " 'class_identity.txt',\n",
              " 'list_attribute.txt',\n",
              " 'gender_classification.xlsx',\n",
              " 'Images']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_list = os.listdir(data_path+'/Images')"
      ],
      "metadata": {
        "id": "bZGqLTQHNpzv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca file list_attribute.txt yang berisi informasi atribut gambar. Merapikan data dengan separasi spasi dan skip kolom metadata\n",
        "data = pd.read_csv(data_path+'/list_attribute.txt', sep='\\s+', skiprows=1)\n",
        "\n",
        "# images_list berisi nama file 5000 gambar yang benar-benar ada.\n",
        "# Kode ini menyaring agar hanya atribut gambar tersebut yang diambil.\n",
        "filtered_data = data[data.index.isin(images_list)]\n",
        "\n",
        "# Hanya kolom 'Male' yang diambil dari dataset. reset_index() mengubah nama gambar dari index menjadi kolom biasa.\n",
        "filtered_data = filtered_data[['Male']].reset_index()\n",
        "\n",
        "# Kolom yang berisi nama gambar diubah namanya menjadi image_id agar lebih jelas.\n",
        "filtered_data = filtered_data.rename(columns={'index': 'image_id'})\n",
        "\n",
        "# Awalnya data 'Male' berisi 1 (laki-laki) dan -1 (bukan laki-laki). Diubah menjadi 1 (laki-laki) dan 0 (bukan laki-laki) supaya cocok untuk model machine learning.\n",
        "filtered_data['Male'] = filtered_data['Male'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "# Buat variabel filtered_data dengan data\n",
        "data = filtered_data\n",
        "\n",
        "print(data.head())\n",
        "print(data.shape)\n",
        "print(\"Unique values in 'Male' column after conversion:\", data['Male'].unique())"
      ],
      "metadata": {
        "id": "iT0VLH-D_j8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3b5d29-a253-44ef-855b-c3d94275e801"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-333735229.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  data = pd.read_csv(data_path+'/list_attribute.txt', sep='\\s+', skiprows=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     image_id  Male\n",
            "0  000051.jpg     1\n",
            "1  000052.jpg     1\n",
            "2  000352.jpg     1\n",
            "3  000409.jpg     1\n",
            "4  000545.jpg     1\n",
            "(1768, 2)\n",
            "Unique values in 'Male' column after conversion: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informasi dataset\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJVc6yioEVBJ",
        "outputId": "a9220747-bdea-4cc4-97f8-f1da39cd55c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1768 entries, 0 to 1767\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   image_id  1768 non-null   object\n",
            " 1   Male      1768 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 27.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GYukcODEk1T",
        "outputId": "ba91f8eb-caa9-4ef2-da67-817ff333ffc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5d20d0ca"
      },
      "source": [
        "# @title\n",
        "!pip install imagehash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imagehash\n",
        "from PIL import Image\n",
        "\n",
        "# Check for duplicate images\n",
        "hashes = {}\n",
        "duplicate_images = []\n",
        "\n",
        "for image_name in images_list:\n",
        "    image_path = os.path.join(data_path, 'Images', image_name)\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        img_hash = str(imagehash.average_hash(img))\n",
        "        if img_hash in hashes:\n",
        "            duplicate_images.append((image_name, hashes[img_hash]))\n",
        "        else:\n",
        "            hashes[img_hash] = image_name\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process image {image_name}: {e}\")\n",
        "\n",
        "if duplicate_images:\n",
        "    print(\"Duplicate images found:\")\n",
        "    for img1, img2 in duplicate_images:\n",
        "        print(f\"- {img1} is a duplicate of {img2}\")\n",
        "else:\n",
        "    print(\"No duplicate images found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8kdLrdiEqGe",
        "outputId": "aa1d5143-d080-4ea0-c799-559309d7c47c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate images found:\n",
            "- 098446.jpg is a duplicate of 098446 (1).jpg\n",
            "- 100409.jpg is a duplicate of 100409 (1).jpg\n",
            "- 138425.jpg is a duplicate of 138425 (1).jpg\n",
            "- 099764.jpg is a duplicate of 099764 (1).jpg\n",
            "- 046845.jpg is a duplicate of 046845 (1).jpg\n",
            "- 070893.jpg is a duplicate of 070893 (1).jpg\n",
            "- 167323.jpg is a duplicate of 167323 (1).jpg\n",
            "- 175928.jpg is a duplicate of 175928 (1).jpg\n",
            "- 161746.jpg is a duplicate of 161746 (1).jpg\n",
            "- 168979 (1).jpg is a duplicate of 168979 (2).jpg\n",
            "- 168979.jpg is a duplicate of 168979 (2).jpg\n",
            "- 183111.jpg is a duplicate of 183111(1).jpg\n",
            "- 182793.jpg is a duplicate of 182793(1).jpg\n",
            "- 044908.jpg is a duplicate of 044908 (1).jpg\n",
            "- 199994.jpg is a duplicate of 199994 (1).jpg\n",
            "- 182912(1).jpg is a duplicate of 182912.jpg\n",
            "- 072921.jpg is a duplicate of 072921 (1).jpg\n",
            "- 123213.jpg is a duplicate of 123213 (1).jpg\n",
            "- 150707.jpg is a duplicate of 178562.jpg\n",
            "- 147959.jpg is a duplicate of 147959 (1).jpg\n",
            "- 155434.jpg is a duplicate of 155434 (1).jpg\n",
            "- 074149.jpg is a duplicate of 074149 (1).jpg\n",
            "- 004109.jpg is a duplicate of 004109 (1).jpg\n",
            "- 000409.jpg is a duplicate of 000409 (1).jpg\n",
            "- 008096.jpg is a duplicate of 008096 (1).jpg\n",
            "- 025662.jpg is a duplicate of 025662 (1).jpg\n",
            "- 039075 (1).jpg is a duplicate of 039075 (2).jpg\n",
            "- 110815.jpg is a duplicate of 110815 (1).jpg\n",
            "- 039075.jpg is a duplicate of 039075 (2).jpg\n",
            "- 109263.jpg is a duplicate of 180686.jpg\n",
            "- 055187.jpg is a duplicate of 055187 (1).jpg\n",
            "- 024441.jpg is a duplicate of 183923.jpg\n",
            "- 024030.jpg is a duplicate of 024030 (1).jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle duplicate images by removing one copy of each duplicate\n",
        "# Create a set of duplicate image names to remove\n",
        "duplicate_image_names_to_remove = set()\n",
        "for img1, img2 in duplicate_images:\n",
        "    # Decide which image to remove, for simplicity, remove the one with (1) or (2) in the name first\n",
        "    if \"(1)\" in img1 or \"(2)\" in img1:\n",
        "        duplicate_image_names_to_remove.add(img1)\n",
        "    elif \"(1)\" in img2 or \"(2)\" in img2:\n",
        "        duplicate_image_names_to_remove.add(img2)\n",
        "    else:\n",
        "        # If no (1) or (2) in name, just remove the second image found\n",
        "        duplicate_image_names_to_remove.add(img2)\n",
        "\n",
        "# Filter images_list to remove duplicate images\n",
        "images_list_filtered = [image for image in images_list if image not in duplicate_image_names_to_remove]\n",
        "\n",
        "print(f\"Original number of images: {len(images_list)}\")\n",
        "print(f\"Number of duplicate images removed: {len(duplicate_image_names_to_remove)}\")\n",
        "print(f\"Number of images after removing duplicates: {len(images_list_filtered)}\")\n",
        "\n",
        "# Update the images_list to the filtered list for subsequent steps\n",
        "images_list = images_list_filtered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sexpz9aYHBpx",
        "outputId": "74ad8d5c-0ee4-4c70-b6ad-c391241d066f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of images: 1802\n",
            "Number of duplicate images removed: 33\n",
            "Number of images after removing duplicates: 1769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe with the filtered image list\n",
        "filtered_images_df = pd.DataFrame({'image_id': images_list})\n",
        "\n",
        "# Merge with the original data to keep the 'Male' column\n",
        "data_filtered = pd.merge(filtered_images_df, data, on='image_id', how='left')\n",
        "\n",
        "print(\"Shape of the new filtered dataframe:\", data_filtered.shape)\n",
        "print(data_filtered.head())\n",
        "\n",
        "# Update the 'data' variable to use the filtered dataframe for subsequent steps\n",
        "data = data_filtered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvjyL4VjHfvb",
        "outputId": "28f4e7e3-3eea-4c3c-9711-7c79d60d3e8c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the new filtered dataframe: (1769, 2)\n",
            "     image_id  Male\n",
            "0  122740.jpg   0.0\n",
            "1  128816.jpg   1.0\n",
            "2  133834.jpg   0.0\n",
            "3  095987.jpg   1.0\n",
            "4  128545.jpg   0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68073209",
        "outputId": "533c5350-586b-443d-f2ac-368e7c1f28d7"
      },
      "source": [
        "# Drop rows with NaN values in the 'Male' column\n",
        "data = data.dropna(subset=['Male'])\n",
        "\n",
        "print(\"Shape of data after dropping NaN:\", data.shape)\n",
        "print(\"Number of NaN values in 'Male' column:\", data['Male'].isnull().sum())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data after dropping NaN: (1765, 2)\n",
            "Number of NaN values in 'Male' column: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets with a 80:20 ratio\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wqq-6PUZdGRO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "vlqeTieFWUTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenderDataset(Dataset):\n",
        "    def __init__(self, data, image_folder_path, transform=None):\n",
        "        self.data = data\n",
        "        self.image_folder_path = image_folder_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder_path, self.data.iloc[idx, 0])\n",
        "        # please define image convertion technique to RGB here\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        gender = self.data.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(int(gender), dtype=torch.long)"
      ],
      "metadata": {
        "id": "4OqB-qUm_nfm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),           # resize ke 224x224 (ukuran input Resnet D)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # augmentasi: flipping kiri/kanan\n",
        "    transforms.ColorJitter(                  # augmentasi: variasi warna/kontras\n",
        "        brightness=0.2,\n",
        "        contrast=0.2,\n",
        "        saturation=0.2,\n",
        "        hue=0.1\n",
        "    ),\n",
        "\n",
        "    transforms.ToTensor(),                   # ubah ke tensor [0,1]\n",
        "    transforms.Normalize(                    # normalisasi pakai mean & std ImageNet\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "wPVfdZZV_pFs"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = GenderDataset(train_data, image_folder_path=os.path.join(data_path, \"Images\"), transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = GenderDataset(test_data, os.path.join(data_path, \"Images\"), transform=transform)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "X73R5VKe_qeM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "TWLDlYSVWWyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please define the model (VGG/GoogleNet/ResNet) here\n",
        "model = resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Add a dropout layer before the final fully connected layer\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(p=0.5), # You can adjust the dropout probability (p) here\n",
        "    nn.Linear(num_ftrs, 2)  # Output layer for 2 classes (male/female)\n",
        ")"
      ],
      "metadata": {
        "id": "jUuOH-ra_r5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7818c9-f6df-41fa-83a1-53261d876568"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) #Gunakan optimizer Adam agar model lebih konvergen, gunakan juga weight decay agar weight/ bobot tidak terlalu besar\n",
        "criterion = nn.CrossEntropyLoss() #CrossEntropyLoss untuk multiclass classification"
      ],
      "metadata": {
        "id": "N2LJMgxPIaQf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "abgEJucmWyp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, use_gpu=torch.cuda.is_available(), num_epochs=10, patience=5, min_delta=0.001):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) # buat copy / model cadangan\n",
        "    best_acc = 0.0 # Set akurasi terbaik mulai dari 0\n",
        "\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    epochs_no_improve = 0 # Variabel epochs_no_improve dipakai untuk menghitung berapa kali berturut-turut akurasi test/validasi tidak membaik. Training berhenti otomatis ketika sudah jelas tidak ada perbaikan, hal ini dapat meminimalisir overfitting\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and evaluation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # alat ukur yang bikin kita tahu apakah overfitting terjadi.\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloaders[phase]:\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # wrap them in Variable\n",
        "                if use_gpu: # Gunakan GPU jika ada (agar proses training lebih cepat)\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else: # Jika tidak ada GPU, gunakan CPU (lebih lambat dari GPU)\n",
        "                    inputs = Variable(inputs)\n",
        "                    labels = Variable(labels)\n",
        "                    # Jika training berjalan lambat, ada potensi training berhenti di tengah jalan, hal ini akan menyebabkan model underfitting\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad() # mengosongkan gradien lama sebelum hitung gradien baru.\n",
        "                # Jika tiap batch dilakukan zero_grad, Model akan update bobot dengan informasi yang jernih, sehingga akurasi train & test lebih stabil.\n",
        "\n",
        "                # forward\n",
        "                # ResNet50 only outputs one value\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward() # inti dari deep learning. Tanpa ini, bobot tidak akan pernah belajar dari kesalahan.\n",
        "                    optimizer.step() # kalau ini tidak ada, model akan stuck dengan bobot awal (tidak ada perbaikan).\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.data * inputs.size(0) # Multiply by batch size for correct loss calculation\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] # Convert to double for accurate division\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc.item())\n",
        "            else:\n",
        "                test_acc_history.append(epoch_acc.item())\n",
        "\n",
        "            # deep copy the model if test accuracy improved\n",
        "            if phase == 'test':\n",
        "                if epoch_acc > best_acc + min_delta:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    if epochs_no_improve == patience:\n",
        "                        print(\"Early stopping!\")\n",
        "                        time_elapsed = time.time() - since\n",
        "                        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "                            time_elapsed // 60, time_elapsed % 60))\n",
        "                        print('Best test Accuracy: {:4f}'.format(best_acc)) # Corrected print statement\n",
        "                        model.load_state_dict(best_model_wts)\n",
        "                        return model, train_acc_history, test_acc_history\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Accuracy: {:4f}'.format(best_acc)) # Corrected print statement\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_acc_history, test_acc_history"
      ],
      "metadata": {
        "id": "8QN5AiKU_7tI"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloders = {\n",
        "    \"train\":train_loader, \"test\":test_loader\n",
        "}\n",
        "dataset_sizes= {\n",
        "    \"train\":len(train_set), \"test\":len(test_set)\n",
        "}"
      ],
      "metadata": {
        "id": "FA70lw6QAzRp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "if use_gpu:\n",
        "  model = model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PtYpHMMCA3YR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, dataloders, dataset_sizes, criterion, optimizer, use_gpu, 10)"
      ],
      "metadata": {
        "id": "_yFxAf6JA5pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38033430-55e5-40e4-f787-de68aaec861b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.2571 Acc: 0.8874\n",
            "test Loss: 0.1410 Acc: 0.9320\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.1016 Acc: 0.9625\n",
            "test Loss: 0.0627 Acc: 0.9688\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0447 Acc: 0.9858\n",
            "test Loss: 0.1148 Acc: 0.9603\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0308 Acc: 0.9873\n",
            "test Loss: 0.0688 Acc: 0.9717\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0241 Acc: 0.9901\n",
            "test Loss: 0.0630 Acc: 0.9773\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0335 Acc: 0.9887\n",
            "test Loss: 0.1037 Acc: 0.9603\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0668 Acc: 0.9731\n",
            "test Loss: 0.0951 Acc: 0.9575\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0450 Acc: 0.9830\n",
            "test Loss: 0.1387 Acc: 0.9518\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0235 Acc: 0.9922\n",
            "test Loss: 0.1067 Acc: 0.9603\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0195 Acc: 0.9936\n",
            "test Loss: 0.1022 Acc: 0.9518\n",
            "Early stopping!\n",
            "Training complete in 2m 53s\n",
            "Best test Accuracy: 0.977337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "EXpMpLXGW2_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, target_labels):\n",
        "    # please define the evaluation function here\n",
        "    model.eval() # Set model to evaluate mode\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Print classification report\n",
        "    print(classification_report(all_labels, all_preds, target_names=target_labels))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "ujCwmsBgCGir"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the trained model from the tuple returned by train_model\n",
        "trained_model, train_acc_history, test_acc_history = model\n",
        "\n",
        "# Now pass the actual model object to the evaluation function\n",
        "evaluate_model(trained_model, dataloders['test'], [\"female\", \"male\"])"
      ],
      "metadata": {
        "id": "R92ueXtqA7gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40666c26-aacf-4a0e-fe6f-a0302ebaf948"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.99      0.97      0.98       210\n",
            "        male       0.96      0.98      0.97       143\n",
            "\n",
            "    accuracy                           0.97       353\n",
            "   macro avg       0.97      0.98      0.97       353\n",
            "weighted avg       0.97      0.97      0.97       353\n",
            "\n",
            "Confusion Matrix:\n",
            "[[204   6]\n",
            " [  3 140]]\n"
          ]
        }
      ]
    }
  ]
}
